{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, GRU\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocab_size = 80000\n",
    "embedding_dim = 100\n",
    "max_len = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath_x = './X_train.txt'\n",
    "filePath_y = './Y_train.txt'\n",
    "filePath_valx = './X_valid.txt'\n",
    "filePath_valy = './Y_valid.txt'\n",
    "\n",
    "with open(filePath_valx, 'rb') as lf:\n",
    "    X_valid = pickle.load(lf)\n",
    "\n",
    "with open(filePath_valy, 'rb') as lf:\n",
    "    Y_valid = pickle.load(lf)\n",
    "    \n",
    "with open(filePath_x, 'rb') as lf:\n",
    "    X_train = pickle.load(lf)\n",
    "\n",
    "with open(filePath_y, 'rb') as lf:\n",
    "    Y_train = pickle.load(lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11397, 12)\n",
      "(880525, 12)\n"
     ]
    }
   ],
   "source": [
    "Y_train_s = Y_train\n",
    "Y_valid_s = Y_valid\n",
    "\n",
    "Y_train_s = np.array(Y_train_s)\n",
    "Y_valid_s = np.array(Y_valid_s)\n",
    "\n",
    "index_14 = []\n",
    "for idx, y in enumerate(Y_train):\n",
    "    if y[14] == 1:\n",
    "        #print(\"Yes\")\n",
    "        index_14.append(idx)\n",
    "#print(index_14)\n",
    "\n",
    "index_9 = []\n",
    "for idx, y in enumerate(Y_train):\n",
    "    if y[9] == 1:\n",
    "        #print(\"Yes\")\n",
    "        index_9.append(idx)\n",
    "#print(index_9)\n",
    "\n",
    "index_13 = []\n",
    "for idx, y in enumerate(Y_valid):\n",
    "    if y[13] == 1:\n",
    "        #print(\"Yes\")\n",
    "        index_13.append(idx)\n",
    "#print(index_13)\n",
    "\n",
    "index_8 = []\n",
    "for idx, y in enumerate(Y_valid):\n",
    "    if y[8] == 1:\n",
    "        #print(\"Yes\")\n",
    "        index_8.append(idx)\n",
    "#print(index_8)\n",
    "\n",
    "for idx in index_14:\n",
    "    Y_train_s[idx][4] = 1\n",
    "for idx in index_9:\n",
    "    Y_train_s[idx][13] = 1\n",
    "    \n",
    "Y_train_s = np.delete(Y_train_s, [0,9,14], axis=1)\n",
    "\n",
    "for idx in index_13:\n",
    "    Y_valid_s[idx][3] = 1\n",
    "for idx in index_8:\n",
    "    Y_valid_s[idx][12] = 1\n",
    "    \n",
    "Y_valid_s = np.delete(Y_valid_s, [8,13], axis=1)\n",
    "\n",
    "Y_valid = Y_valid_s\n",
    "Y_train = Y_train_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [[x,y] for x, y in zip(X_train, Y_train)]\n",
    "random.shuffle(tmp)\n",
    "X_train = [n[0] for n in tmp]\n",
    "Y_train = [n[1] for n in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11397, 12)\n",
      "(880525, 12)\n",
      "(880525, 260)\n",
      "(11397, 260)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "print(Y_valid.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_r, X_valid_r, Y_test_r, Y_valid_r = train_test_split(X_valid, Y_valid, test_size = 0.5, random_state=1, shuffle=True)\n",
    "category = 12\n",
    "\n",
    "inputs = Input(shape=(max_len,))\n",
    "inputs = Embedding(vocab_size, embedding_dim)(inputs)\n",
    "inputs = GRU(max_len)(inputs)\n",
    "output = Dense(category, activation='softmax')(inputs)\n",
    "model = Model(inputs=inputs, outputs=output) \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, epochs=40, batch_size=128 ,validation_data=(X_valid_r, Y_valid_r))\n",
    "results = model.evaluate(X_test_r, Y_test_r)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be804b82f4b6c4507defaecc1db297e0af07cd9427439add2fdfb9df30e508f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
